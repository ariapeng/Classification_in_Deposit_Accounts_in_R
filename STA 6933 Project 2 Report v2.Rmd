---
title: "STA 6933 Advanced Topics in Statistical Learning"
author: |
  | Project 2
  | Spring 2022 
  | Sanbrina Fautheree, Yahui Peng, Marc Sandoval
date: "5/10/2022"
header_includes:
- \usepackage{amsmath}
- \usepackage{amssymb}
- \usepackage{amsthm}
abstract: A bank compiled customer information during a campaign to identify the cause for revenue decline, which they concluded was caused by existing customers not obtaining long-term deposit accounts. In the project, we attempt to identify which customers are likely to obtain long-term deposit accounts based on customer information and demographics. Since the compiled data set mainly consists of categorical predictors, we will focus on tree-based methodologies in this project.   
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE, paged.print=FALSE)
```
# Overview

# Data Structure
The banking data consists of 15 predictors and 1 binary response variable, among which 10 predictors are nominal and 6 predictors contain nulls.

```{r}
#plot results of script
library(kableExtra)
library(dplyr)
library(e1071)

#create table for data
pred_vars <- c("age","job","marital","education","default","housing","loan","contact","month", "dayofweek","duration","campaign","pdays","previous","poutcome")

Type <- c("numeric","nominal","nominal","nominal","nominal","nominal","nominal","nominal","nominal","nominal","numeric","numeric","numeric","numeric","nominal")
Null_ind <- c("no","yes","yes","yes","yes","yes","yes","no","no","no","no","no","no","no","no")

data_t <- data.frame(pred_vars, Type,Null_ind)

names(data_t) <- c("Predictor","Data Type","Contains Nulls")
knitr::kable(data_t, col.name = names(data_t),
             caption = "Predictor Variables") %>%
            kable_styling("striped")%>%
  kable_styling(latex_options = "hold_position")
```
  
As **pdays** represents the number of days that passed by after the client was last contacted from a previous campaign (999 means the client was not previously contacted). Therefore, for better visualization and interpretation, we encode **pdays** == 999 to NA for EDA purposes only, but they are immediately encoded back to 999 after EDA.  
Summary statistics and Box-plots suggest outliers exist for all predictors, however, tree-based models are the models of interest for this project and are outlier-insensitive. Therefore, we do not resolve the outliers.  

```{r}
# Load libraries ----------------------------------------------------------
library(caret)
library(Hmisc)
library(VIM) # aggr_plot() for value missing patterns

# Read the data -----------------------------------------------------------
data <- read.csv('D:/Yahui/Textbooks/STA6933_Adv Stat Mining/Project2/Banking Dataset Classification data.csv')

## Miscategorized data -----------------------------------------------------

# convert y to 0 if no; 1 if yes
data$y <- factor(data$y, levels =c("no","yes"), labels =c(0,1))

## Summary stats for numeric vars ----------------------------------
summary(data[,c("age","duration","campaign","pdays","previous")])

## Boxplots -----------------------------------------------------
col <- c("#61a2bc","#b93f1d",'#ab8fbe',"#d3a426","#88b998","#aaa197","#d67900","#cb7580")
data.numeric <- data[,c("age","duration","campaign","pdays","previous")]
par(mfrow=c(1,5)) 
for (i in 1:5) {
  boxplot(data.numeric[,i], main=colnames(data.numeric)[i],col=col[i])
}
```

Pairwise scatterplots, correlation matrix, and histograms for numeric preditors are shown below. First, in pairwise scatterplots, points are colored in red and grey for y = 1 and 0, respectively. We observe that clients with longer **duration** is more likely to have subscribed a term deposit (y = 1). No obvious trend is observed between y and other numeric predictors. Second, The font size of the correlation coefficients displayed in upper panel are proportional to the magnitude of the value. Therefore, no strong correlation presents between each pair of numeric predictors. Last, histograms show all numeric predictors are skewed.  

```{r}
## Pairwise scatterplots
panel.hist <- function(x, ...){
  #from help of pairs
  usr <- par("usr"); on.exit(par(usr))
  par(usr = c(usr[1:2], 0, 1.5) )
  h <- hist(x, plot = FALSE)
  breaks <- h$breaks; nB <- length(breaks)
  y <- h$counts; y <- y/max(y)
  rect(breaks[-nB], 0, breaks[-1], y,col = "#61a2bc")
}

panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...){
  #from help of pairs
  usr <- par("usr"); on.exit(par(usr))
  par(usr = c(0, 1, 0, 1))
  r <- abs(cor(x, y,use="pairwise.complete.obs"))
  txt <- format(c(r, 0.123456789), digits = digits)[1]
  txt <- paste0(prefix, txt)
  if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
  text(0.5, 0.5, txt, cex = 1.25*cex.cor * r,col="#402a34")
}

# pairs(data[,-9],col="steelblue")
pairs(data[,c("age","duration","campaign","pdays","previous")], 
      lower.panel = panel.smooth,
      upper.panel = panel.cor,col=ifelse(data$y==0, "#625a50", "firebrick"),
      diag.panel = panel.hist
)

data$pdays[is.na(data$pdays)] <- 999
```
  
Missing completely at random (MCAR) is the desirable scenario in case of missing data. Assuming data is MCAR, too much missing data can be a problem, too. Usually, a safe maximum threshold is 5% of the total for large datasets. The aggregation plot helps us understanding that almost 74% of the samples are not missing any information, 21% are missing the **default** value, and the remaining ones show other missing patterns. We probably should leave the feature **default** out. 
  
```{r}
require(VIM)
## Missing Values -----------------------------------------------------------

# Plot the aggregated patterns of values
aggr(data, col=c('steelblue','firebrick'), numbers=TRUE, sortVars=TRUE, 
                  labels=names(data), cex.axis=.6, gap=3, ylab=c("Histogram of missing data","Pattern"))

# The zero values are not assigned at random, therefore are non-ignorable. 
```

Bivariate analysis for ten categorical predictors are shown below. It is observed that **month** dec, mar, oct, and sep show noticeable probability of y=1, which is nearly 50 %, indicating possible lack of impact of these month categories on the response.  

```{r}
## Bivariate Analysis of Categorical predictors -----------------------------

library(ggplot2)
library(ggpubr)
pl1 <- ggplot(data = data, aes(x = as.factor(data$job), fill = y))+
  geom_bar()+
  xlab("job") +
  theme_classic()
pl2 <- ggplot(data = data, aes(x = as.factor(marital), fill = y))+
  geom_bar()+
  xlab("marital") +
  theme_classic()

pl3 <- ggplot(data = data, aes(x = as.factor(education), fill = y))+
  geom_bar()+
  xlab("education") +
  theme_classic()

pl4 <- ggplot(data = data, aes(as.factor(default),fill = y))+
  geom_bar()+
  xlab("default") +
  theme_classic()

pl5 <- ggplot(data = data, aes(as.factor(housing),fill = y))+
  geom_bar()+
  xlab("housing") +
  theme_classic()

pl6 <- ggplot(data = data, aes(as.factor(loan),fill = y))+
  geom_bar()+
  xlab("loan") +
  theme_classic()

pl7 <- ggplot(data = data, aes(as.factor(contact),fill = y))+
  geom_bar()+
  xlab("contact") +
  theme_classic()

pl8 <- ggplot(data = data, aes(as.factor(month),fill = y))+
  geom_bar()+
  xlab("month") +
  theme_classic()

pl9 <- ggplot(data = data, aes(as.factor(day_of_week),fill = y))+
  geom_bar()+
  xlab("day_of_week") +
  theme_classic()

pl10 <- ggplot(data = data, aes(as.factor(poutcome),fill = y))+
  geom_bar()+
  xlab("poutcome") +
  theme_classic()

pl1
pl3
ggarrange(pl2, pl4, pl5, pl6, pl7, pl10, pl8, pl9, ncol = 2, nrow = 5, common.legend = TRUE, legend = "bottom")

# convert "unknown" to nulls
data[data=="unknown"] <- NA

# convert pdays = 999 to NA
data$pdays[data$pdays==999] <- -1
```

## 

*Data Imputation*     


*Imbalanced Data*     
     
We observe that our response variable is imbalanced, which may cause poor model performance in the minority class. We applied the *SMOTE()* algorithm to create new observation in the minority class, which uses the k-nearest neighbor algorithm to generate new observation. The resulting training data set is more balanced.  

```{r,echo = FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
# balance of response variable ----
table(data$y)
prop.table(table(data$y))

#create table balance
Class <- c("Y=0","Y=1")
Cnt <- c("29,238","3,712")
prc <- c(0.887,0.113)

data_t <- data.frame(Class, Cnt,prc)

names(data_t) <- c("Class","Count","%")
knitr::kable(data_t, col.name = names(data_t),
             caption = "Response Variable Proportion") %>%
            kable_styling("striped")%>%
  kable_styling(latex_options = "hold_position")
```


```{r,echo = FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
#create table balance
Class <- c("Y=0","Y=1")
Cnt <- c("23,391","17,820")
prc <- c(0.568,0.432)

data_t <- data.frame(Class, Cnt,prc)

names(data_t) <- c("Class","Count","%")
knitr::kable(data_t, col.name = names(data_t),
             caption = "Response Variable Proportion after Balancing") %>%
            kable_styling("striped")%>%
  kable_styling(latex_options = "hold_position")
```



```{r, eval=F}
## Feature Selection
load("D:/Yahui/Textbooks/STA6933_Adv Stat Mining/Project2/Project2_data.RData")
data_train$pdays[data_train$pdays == 999] <- NA # encode pday = 999 to NA then cap the outliers

# Resolve skewness ----
# Calculate the skewness of of each predictor.
apply(data_train[,c("age","duration","campaign","pdays","previous")], 2, function(x)skewness(na.omit(x)))

# It is observed that predictors *Insulin*, *DiabetesPedigreeFunction*, and *Age* are highly skewed.

# Box-cox transformation is used to deal with skewness and therefore might improve the classification model.
BoxCoxTrans(data_train$duration) # no transformation is applied
BoxCoxTrans(data_train$campaign) # take reciprocal, that is 1/campaign
BoxCoxTrans(data_train$pdays) # no transformation is applied
BoxCoxTrans(data_train$previous) # no transformation is applied
```

The skewness of numeric predictors are checked, and Box-Cox transformation suggests a reverse on campaign. Comparative histograms show that skewness is relieved after the transformation.   

```{r}
# plot comparison histograms
load("D:/Yahui/Textbooks/STA6933_Adv Stat Mining/Project2/Project2_data.RData")
par(mfrow=c(1,2))
hist(data_train$campaign, prob=T,xlab = "Campaign", col= "#9a8f83",main="Campaign (Before)")
hist(1/data_train$campaign, prob=T,xlab = "1/Campaign", col= "#cac4be",main="Campaign (After)")

data_train$rev.campaign <- 1/data_train$campaign
```
   
Near-zero variance predictors are further obtained. Considering that default have 21% missing in the original data set, and has near-zero variance after imputation, we should consider drop it out. Additionally, job 3, 4, 6, 7, 9, 11, education 2 and 5, month 3, 9, 10, and 12 show near-zero variance.  

```{r}
# Near-zero variance vars -------------------------------------------------
load("D:/Yahui/Textbooks/STA6933_Adv Stat Mining/Project2/Project2_data.RData")
names(data_train)[nearZeroVar(data_train)] 
data_train$pdays[is.na(data_train$pdays)] <- 999
```

# Analysis

*Models*     

```{r, echo = FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
#create table balance
model_type <- c("Logistic Model","Random Forest","Boosted Model", "BART Model", "C5.0 Model")
err_tr <- c("0.3262","0.1466","0.2182", "0.1421","0.1267")
err_te <- c("0.1490","0.1287","0.1283", "0.1279","0.1306")

data_t <- data.frame(model_type,err_tr,err_te)

names(data_t) <- c("Model","Training Error","Testing Error")
knitr::kable(data_t, col.name = names(data_t),
             caption = "Model Performance--Misclassification Error") %>%
            kable_styling("striped")%>%
  kable_styling(latex_options = "hold_position")
```

*ROC Curves*     

```{r, eval=TRUE, echo = FALSE, message=FALSE, warning=FALSE,fig.width=3, fig.height=3, paged.print=FALSE}
# ROC Curves
library(ggplot2)
library(pROC)
load("D:/Yahui/Textbooks/STA6933_Adv Stat Mining/Project2/predictions.RData")

# Logistic Model
rocobj <- roc(predictions$y, predictions$logistic)
auc <- round(auc(predictions$y, predictions$logistic),4)
ggroc(rocobj, colour = 'steelblue', size = 1) +
  ggtitle(paste0('ROC Curve: Logistic Model ', '(AUC = ', auc, ')')) +
  theme(plot.title = element_text(size = 8))

# Random Forest
rocobj <- roc(predictions$y, predictions$RF.1)
auc <- round(auc(predictions$y, predictions$RF.1),4)
ggroc(rocobj, colour = 'steelblue', size = 1) +
  ggtitle(paste0('ROC Curve: Random Forest ', '(AUC = ', auc, ')')) +
  theme(plot.title = element_text(size = 8))

# Boosted Model
rocobj <- roc(predictions$y, predictions$Boost)
auc <- round(auc(predictions$y, predictions$Boost),4)
ggroc(rocobj, colour = 'steelblue', size = 1) +
  ggtitle(paste0('ROC Curve: Boosted Model ', '(AUC = ', auc, ')')) +
  theme(plot.title = element_text(size = 8))

# BART Model
rocobj <- roc(predictions$y, predictions$BART)
auc <- round(auc(predictions$y, predictions$BART),4)
ggroc(rocobj, colour = 'steelblue', size = 1) +
  ggtitle(paste0('ROC Curve: BART Model ', '(AUC = ', auc, ')')) +
  theme(plot.title = element_text(size = 8))

# C5.0 Model
rocobj <- roc(predictions$y, predictions$C50.1)
auc <- round(auc(predictions$y, predictions$C50.1),4)
ggroc(rocobj, colour = 'steelblue', size = 1) +
  ggtitle(paste0('ROC Curve: C5.0 Model ', '(AUC = ', auc, ')')) +
  theme(plot.title = element_text(size = 8))
```



# Conclusion
